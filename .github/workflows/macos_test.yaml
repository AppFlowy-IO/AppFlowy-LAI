name: Run macOS tests

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  run_test:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.LOCAL_AI_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.LOCAL_AI_AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.LOCAL_AI_AWS_REGION }}

      - name: Download artifact from S3
        run: |
          aws s3 cp s3://appflowy-local-ai-test/macos-latest/AppFlowyAI_debug.zip AppFlowyAI_macos-latest_debug.zip
          unzip AppFlowyAI_macos-latest_debug.zip -d AppFlowyAI
          cd AppFlowyAI
          ls
        shell: bash

      - name: Prepare env
        run: |
          ls
          ABS_PATH=$(pwd)
          chat_bin_path=$ABS_PATH/AppFlowyAI/AppFlowyAI.app/Contents/MacOS/appflowy_ai_plugin
          embedding_bin_path=$ABS_PATH/AppFlowyAI/AppFlowyAI.app/Contents/MacOS/appflowy_embedding_plugin
          
          cp dev.env .env
          sed -i '' 's|RUST_LOG=.*|RUST_LOG=trace|' .env
          
          # binary
          sed -i '' "s|CHAT_BIN_PATH=.*|CHAT_BIN_PATH=$chat_bin_path|" .env
          sed -i '' "s|EMBEDDING_BIN_PATH=.*|EMBEDDING_BIN_PATH=$embedding_bin_path|" .env
          # model
          sed -i '' "s|LOCAL_AI_MODEL_DIR=.*|LOCAL_AI_MODEL_DIR=/Users/weidongfu/Documents/LLMModel|" .env
          sed -i '' 's|LOCAL_AI_CHAT_MODEL_NAME=.*|LOCAL_AI_CHAT_MODEL_NAME=Mistral-7B-Instruct-v0.3.Q4_K_M.gguf|' .env
          sed -i '' 's|LOCAL_AI_EMBEDDING_MODEL_NAME=.*|LOCAL_AI_EMBEDDING_MODEL_NAME=all-MiniLM-L12-v2.Q4_0.gguf|' .env
          cat .env
        shell: bash


      - name: Run tests
        run: cargo test ci_
        shell: bash

      - name: Cleanup downloaded artifacts
        run: |
          rm -rf AppFlowyAI_macos-latest_debug.zip
          rm -rf AppFlowyAI
